{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e18cee2",
   "metadata": {},
   "source": [
    "# ü§ñ AWS Bedrock - Generaci√≥n de Descripciones y Clasificaci√≥n\n",
    "\n",
    "Este notebook implementa la integraci√≥n con AWS Bedrock para:\n",
    "1. Generar descripciones enriquecidas de clientes\n",
    "2. Clasificar riesgo crediticio usando IA generativa\n",
    "3. Crear dataset enriquecido para entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08dd05e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalar dependencias si es necesario\n",
    "# !pip install boto3 pandas numpy python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e64bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from pathlib import Path\n",
    "import os\n",
    "from typing import Dict, List\n",
    "from botocore.exceptions import ClientError\n",
    "import logging\n",
    "\n",
    "# Configurar logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "print(\"‚úÖ Librer√≠as importadas correctamente\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f6b96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuraci√≥n AWS\n",
    "AWS_REGION = \"us-east-1\"\n",
    "BEDROCK_MODEL_ID = \"anthropic.claude-3-haiku-20240307-v1:0\"\n",
    "\n",
    "print(f\"üîß Regi√≥n configurada: {AWS_REGION}\")\n",
    "print(f\"ü§ñ Modelo Bedrock: {BEDROCK_MODEL_ID}\")\n",
    "print(\"\\n‚ö†Ô∏è  IMPORTANTE: Aseg√∫rate de tener configuradas tus credenciales AWS\")\n",
    "print(\"   - aws configure\")\n",
    "print(\"   - Variables de entorno AWS_ACCESS_KEY_ID y AWS_SECRET_ACCESS_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b08035f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar datos reales del reto\n",
    "data_path = Path(\"../data/credir_risk_reto.xlsx\")\n",
    "\n",
    "print(f\"üìÇ Cargando datos desde: {data_path}\")\n",
    "\n",
    "if data_path.exists():\n",
    "    df = pd.read_excel(data_path)\n",
    "    print(f\"‚úÖ Datos cargados exitosamente\")\n",
    "    print(f\"üìä Forma del dataset: {df.shape}\")\n",
    "    print(f\"üìã Columnas: {list(df.columns)}\")\n",
    "    \n",
    "    # Guardar como CSV para uso futuro\n",
    "    csv_path = \"../data/credit_risk_reto.csv\"\n",
    "    df.to_csv(csv_path, index=False)\n",
    "    print(f\"üíæ Guardado como CSV: {csv_path}\")\n",
    "    \n",
    "    # Mostrar muestra\n",
    "    display(df.head())\n",
    "else:\n",
    "    print(f\"‚ùå Archivo no encontrado: {data_path}\")\n",
    "    print(\"Por favor aseg√∫rate de que el archivo est√© en la carpeta data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6847f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# An√°lisis b√°sico de los datos\n",
    "print(\"üîç AN√ÅLISIS DE LOS DATOS REALES\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(f\"Forma del dataset: {df.shape}\")\n",
    "print(f\"\\nTipos de datos:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "print(f\"\\nValores nulos:\")\n",
    "null_counts = df.isnull().sum()\n",
    "for col, count in null_counts.items():\n",
    "    if count > 0:\n",
    "        print(f\"‚Ä¢ {col}: {count} ({count/len(df)*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\nPrimeras 5 filas:\")\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199bb5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funci√≥n para inicializar cliente Bedrock\n",
    "def init_bedrock_client(region_name: str = AWS_REGION):\n",
    "    \"\"\"\n",
    "    Inicializa el cliente de Bedrock\n",
    "    \"\"\"\n",
    "    try:\n",
    "        client = boto3.client(\n",
    "            service_name='bedrock-runtime',\n",
    "            region_name=region_name\n",
    "        )\n",
    "        \n",
    "        # Test b√°sico\n",
    "        print(f\"‚úÖ Cliente Bedrock inicializado en regi√≥n: {region_name}\")\n",
    "        return client\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error al inicializar Bedrock: {e}\")\n",
    "        print(\"\\nüîß Soluciones posibles:\")\n",
    "        print(\"1. Verificar credenciales AWS: aws configure\")\n",
    "        print(\"2. Verificar permisos para Bedrock\")\n",
    "        print(\"3. Verificar que Bedrock est√© disponible en la regi√≥n\")\n",
    "        return None\n",
    "\n",
    "# Inicializar cliente\n",
    "bedrock_client = init_bedrock_client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b932b388",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funci√≥n para generar descripci√≥n de cliente\n",
    "def generate_description(client, customer_data: dict, model_id: str = BEDROCK_MODEL_ID):\n",
    "    \"\"\"\n",
    "    Genera descripci√≥n narrativa de un cliente usando Bedrock\n",
    "    \"\"\"\n",
    "    \n",
    "    # Crear prompt\n",
    "    prompt = f\"\"\"\n",
    "Como experto en an√°lisis crediticio, genera una descripci√≥n narrativa y profesional de este cliente bancario.\n",
    "\n",
    "Datos del cliente:\n",
    "{json.dumps(customer_data, indent=2, ensure_ascii=False)}\n",
    "\n",
    "Crea una descripci√≥n de 2-3 p√°rrafos que incluya:\n",
    "1. Perfil demogr√°fico y profesional\n",
    "2. Situaci√≥n financiera y vivienda  \n",
    "3. Detalles de la solicitud de cr√©dito\n",
    "\n",
    "La descripci√≥n debe ser objetiva, profesional y √∫til para an√°lisis de riesgo crediticio.\n",
    "\n",
    "Descripci√≥n:\n",
    "\"\"\"\n",
    "    \n",
    "    try:\n",
    "        # Request body para Claude\n",
    "        request_body = {\n",
    "            \"anthropic_version\": \"bedrock-2023-05-31\",\n",
    "            \"max_tokens\": 500,\n",
    "            \"temperature\": 0.1,\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": prompt\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "        \n",
    "        # Llamar a Bedrock\n",
    "        response = client.invoke_model(\n",
    "            modelId=model_id,\n",
    "            body=json.dumps(request_body),\n",
    "            contentType='application/json',\n",
    "            accept='application/json'\n",
    "        )\n",
    "        \n",
    "        # Procesar respuesta\n",
    "        response_body = json.loads(response['body'].read())\n",
    "        description = response_body['content'][0]['text'].strip()\n",
    "        \n",
    "        return description\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error generando descripci√≥n: {e}\")\n",
    "        return f\"Error: {str(e)}\"\n",
    "\n",
    "print(\"‚úÖ Funci√≥n de generaci√≥n de descripciones definida\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef33a132",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funci√≥n para clasificar riesgo crediticio\n",
    "def classify_risk(client, customer_data: dict, description: str, model_id: str = BEDROCK_MODEL_ID):\n",
    "    \"\"\"\n",
    "    Clasifica el riesgo crediticio usando Bedrock\n",
    "    \"\"\"\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "Como analista de riesgo crediticio, eval√∫a este cliente y clasif√≠calo.\n",
    "\n",
    "Datos del cliente:\n",
    "{json.dumps(customer_data, indent=2, ensure_ascii=False)}\n",
    "\n",
    "Descripci√≥n del cliente:\n",
    "{description}\n",
    "\n",
    "Clasifica el riesgo crediticio como:\n",
    "- \"good\" para bajo riesgo (recomendado aprobar)\n",
    "- \"bad\" para alto riesgo (recomendado rechazar)\n",
    "\n",
    "Responde en el siguiente formato JSON:\n",
    "{{\n",
    "    \"prediction\": \"good\" o \"bad\",\n",
    "    \"confidence\": n√∫mero entre 0.0 y 1.0,\n",
    "    \"reasoning\": \"explicaci√≥n breve de la decisi√≥n\"\n",
    "}}\n",
    "\n",
    "Respuesta:\n",
    "\"\"\"\n",
    "    \n",
    "    try:\n",
    "        request_body = {\n",
    "            \"anthropic_version\": \"bedrock-2023-05-31\",\n",
    "            \"max_tokens\": 300,\n",
    "            \"temperature\": 0.1,\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": prompt\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "        \n",
    "        response = client.invoke_model(\n",
    "            modelId=model_id,\n",
    "            body=json.dumps(request_body),\n",
    "            contentType='application/json',\n",
    "            accept='application/json'\n",
    "        )\n",
    "        \n",
    "        response_body = json.loads(response['body'].read())\n",
    "        classification_text = response_body['content'][0]['text'].strip()\n",
    "        \n",
    "        # Intentar parsear JSON\n",
    "        try:\n",
    "            start_idx = classification_text.find('{')\n",
    "            end_idx = classification_text.rfind('}') + 1\n",
    "            \n",
    "            if start_idx != -1 and end_idx != 0:\n",
    "                json_text = classification_text[start_idx:end_idx]\n",
    "                result = json.loads(json_text)\n",
    "                return result\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        # Fallback: clasificaci√≥n b√°sica\n",
    "        if 'good' in classification_text.lower():\n",
    "            return {\"prediction\": \"good\", \"confidence\": 0.6, \"reasoning\": \"Parsed from text\"}\n",
    "        elif 'bad' in classification_text.lower():\n",
    "            return {\"prediction\": \"bad\", \"confidence\": 0.6, \"reasoning\": \"Parsed from text\"}\n",
    "        else:\n",
    "            return {\"prediction\": \"unknown\", \"confidence\": 0.0, \"reasoning\": \"Could not parse\"}\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error en clasificaci√≥n: {e}\")\n",
    "        return {\"prediction\": \"error\", \"confidence\": 0.0, \"reasoning\": f\"Error: {str(e)}\"}\n",
    "\n",
    "print(\"‚úÖ Funci√≥n de clasificaci√≥n de riesgo definida\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7a2463",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probar con un ejemplo antes de procesar todo el dataset\n",
    "if bedrock_client and len(df) > 0:\n",
    "    print(\"üß™ PRUEBA CON UN REGISTRO\")\n",
    "    print(\"=\" * 30)\n",
    "    \n",
    "    # Tomar el primer registro\n",
    "    sample_row = df.iloc[0]\n",
    "    sample_data = sample_row.to_dict()\n",
    "    \n",
    "    print(f\"üìã Datos del cliente de prueba:\")\n",
    "    for key, value in sample_data.items():\n",
    "        print(f\"  {key}: {value}\")\n",
    "    \n",
    "    print(f\"\\nü§ñ Generando descripci√≥n con Bedrock...\")\n",
    "    description = generate_description(bedrock_client, sample_data)\n",
    "    print(f\"üìù Descripci√≥n generada:\")\n",
    "    print(description)\n",
    "    \n",
    "    print(f\"\\nüéØ Clasificando riesgo...\")\n",
    "    classification = classify_risk(bedrock_client, sample_data, description)\n",
    "    print(f\"üîç Clasificaci√≥n:\")\n",
    "    print(json.dumps(classification, indent=2, ensure_ascii=False))\n",
    "    \n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No se puede realizar la prueba:\")\n",
    "    print(\"‚Ä¢ Cliente Bedrock no inicializado o\")\n",
    "    print(\"‚Ä¢ Dataset vac√≠o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f3aedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Procesar un lote peque√±o del dataset (primeros 10 registros para prueba)\n",
    "if bedrock_client and len(df) > 0:\n",
    "    print(\"üîÑ PROCESANDO LOTE DE PRUEBA (10 registros)\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Tomar solo los primeros 10 registros para prueba\n",
    "    sample_df = df.head(10).copy()\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for idx, row in sample_df.iterrows():\n",
    "        print(f\"\\nüì¶ Procesando registro {idx + 1}/10...\")\n",
    "        \n",
    "        try:\n",
    "            customer_data = row.to_dict()\n",
    "            \n",
    "            # Generar descripci√≥n\n",
    "            description = generate_description(bedrock_client, customer_data)\n",
    "            \n",
    "            # Clasificar riesgo\n",
    "            classification = classify_risk(bedrock_client, customer_data, description)\n",
    "            \n",
    "            # Agregar resultados\n",
    "            result = customer_data.copy()\n",
    "            result['bedrock_description'] = description\n",
    "            result['bedrock_prediction'] = classification['prediction']\n",
    "            result['bedrock_confidence'] = classification['confidence']\n",
    "            result['bedrock_reasoning'] = classification['reasoning']\n",
    "            \n",
    "            results.append(result)\n",
    "            \n",
    "            print(f\"‚úÖ Registro {idx + 1} procesado: {classification['prediction']}\")\n",
    "            \n",
    "            # Pausa para evitar rate limiting\n",
    "            time.sleep(2)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error procesando registro {idx + 1}: {e}\")\n",
    "            result = row.to_dict()\n",
    "            result['bedrock_description'] = f\"Error: {str(e)}\"\n",
    "            result['bedrock_prediction'] = \"error\"\n",
    "            result['bedrock_confidence'] = 0.0\n",
    "            result['bedrock_reasoning'] = f\"Error: {str(e)}\"\n",
    "            results.append(result)\n",
    "    \n",
    "    # Crear DataFrame con resultados\n",
    "    enriched_sample = pd.DataFrame(results)\n",
    "    \n",
    "    print(f\"\\n‚úÖ Procesamiento completado\")\n",
    "    print(f\"üìä Registros procesados: {len(enriched_sample)}\")\n",
    "    \n",
    "    # Mostrar resumen\n",
    "    predictions = enriched_sample['bedrock_prediction'].value_counts()\n",
    "    print(f\"\\nüìà Distribuci√≥n de predicciones:\")\n",
    "    for pred, count in predictions.items():\n",
    "        print(f\"  {pred}: {count} ({count/len(enriched_sample)*100:.1f}%)\")\n",
    "    \n",
    "    # Guardar muestra enriquecida\n",
    "    sample_output = \"../data/credit_risk_sample_enriched.csv\"\n",
    "    enriched_sample.to_csv(sample_output, index=False)\n",
    "    print(f\"\\nüíæ Muestra enriquecida guardada: {sample_output}\")\n",
    "    \n",
    "    display(enriched_sample[['bedrock_prediction', 'bedrock_confidence', 'bedrock_description']].head())\n",
    "    \n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No se puede procesar el lote: Cliente Bedrock no disponible\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be6f2920",
   "metadata": {},
   "source": [
    "## üí∞ Estimaci√≥n de Costos\n",
    "\n",
    "Para procesar el dataset completo de 1000 registros:\n",
    "\n",
    "**Claude 3 Haiku:**\n",
    "- Input: ~500 tokens por request √ó 2000 requests = 1M tokens\n",
    "- Output: ~300 tokens por request √ó 2000 requests = 600K tokens  \n",
    "- **Costo estimado: ~$1.50 USD**\n",
    "\n",
    "**Tiempo estimado:** 1-2 horas (con pausas para rate limiting)\n",
    "\n",
    "¬øContinuar con el dataset completo?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e552c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPCIONAL: Procesar dataset completo (solo ejecutar si est√°s seguro)\n",
    "PROCESS_FULL_DATASET = False  # Cambiar a True para procesar todo\n",
    "\n",
    "if PROCESS_FULL_DATASET and bedrock_client and len(df) > 0:\n",
    "    print(\"üöÄ PROCESANDO DATASET COMPLETO\")\n",
    "    print(f\"üìä Total de registros: {len(df)}\")\n",
    "    print(\"üí∞ Costo estimado: ~$1.50 USD\")\n",
    "    print(\"‚è±Ô∏è Tiempo estimado: 1-2 horas\")\n",
    "    \n",
    "    input(\"\\n‚ö†Ô∏è Presiona ENTER para continuar o Ctrl+C para cancelar...\")\n",
    "    \n",
    "    results_full = []\n",
    "    batch_size = 10\n",
    "    \n",
    "    for i in range(0, len(df), batch_size):\n",
    "        batch = df.iloc[i:i+batch_size]\n",
    "        print(f\"\\nüì¶ Procesando lote {i//batch_size + 1}/{(len(df)-1)//batch_size + 1}\")\n",
    "        \n",
    "        for idx, row in batch.iterrows():\n",
    "            try:\n",
    "                customer_data = row.to_dict()\n",
    "                \n",
    "                # Generar descripci√≥n\n",
    "                description = generate_description(bedrock_client, customer_data)\n",
    "                \n",
    "                # Clasificar riesgo\n",
    "                classification = classify_risk(bedrock_client, customer_data, description)\n",
    "                \n",
    "                # Agregar resultados\n",
    "                result = customer_data.copy()\n",
    "                result['bedrock_description'] = description\n",
    "                result['bedrock_prediction'] = classification['prediction']\n",
    "                result['bedrock_confidence'] = classification['confidence']\n",
    "                result['bedrock_reasoning'] = classification['reasoning']\n",
    "                \n",
    "                results_full.append(result)\n",
    "                \n",
    "                if (idx + 1) % 50 == 0:\n",
    "                    print(f\"‚úÖ Procesados {idx + 1} registros\")\n",
    "                \n",
    "                # Pausa para rate limiting\n",
    "                time.sleep(1.5)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Error en registro {idx}: {e}\")\n",
    "                result = row.to_dict()\n",
    "                result['bedrock_description'] = f\"Error: {str(e)}\"\n",
    "                result['bedrock_prediction'] = \"error\"\n",
    "                result['bedrock_confidence'] = 0.0\n",
    "                result['bedrock_reasoning'] = f\"Error: {str(e)}\"\n",
    "                results_full.append(result)\n",
    "    \n",
    "    # Crear DataFrame final\n",
    "    enriched_full = pd.DataFrame(results_full)\n",
    "    \n",
    "    # Guardar dataset enriquecido completo\n",
    "    output_path = \"../data/credit_risk_enriched.csv\"\n",
    "    enriched_full.to_csv(output_path, index=False)\n",
    "    \n",
    "    print(f\"\\nüéâ DATASET COMPLETO PROCESADO\")\n",
    "    print(f\"üìä Total registros: {len(enriched_full)}\")\n",
    "    print(f\"üíæ Guardado en: {output_path}\")\n",
    "    \n",
    "    # Estad√≠sticas finales\n",
    "    final_predictions = enriched_full['bedrock_prediction'].value_counts()\n",
    "    print(f\"\\nüìà Distribuci√≥n final:\")\n",
    "    for pred, count in final_predictions.items():\n",
    "        print(f\"  {pred}: {count} ({count/len(enriched_full)*100:.1f}%)\")\n",
    "        \n",
    "else:\n",
    "    print(\"‚ÑπÔ∏è Dataset completo NO procesado (PROCESS_FULL_DATASET = False)\")\n",
    "    print(\"   Para procesar todo, cambiar PROCESS_FULL_DATASET = True\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a73aa58b",
   "metadata": {},
   "source": [
    "## üìã Pr√≥ximos Pasos\n",
    "\n",
    "1. **‚úÖ An√°lisis exploratorio completado**\n",
    "2. **‚úÖ Integraci√≥n Bedrock funcionando** \n",
    "3. **‚úÖ Muestra enriquecida generada**\n",
    "\n",
    "**Siguientes pasos:**\n",
    "- Entrenar modelo con SageMaker usando datos enriquecidos\n",
    "- Crear API para predicciones en tiempo real\n",
    "- Implementar monitoreo y m√©tricas"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
